{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukritikala/Deep-Learning-Models/blob/main/DL4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5Y3Xj6T16NB",
        "outputId": "f8aa3d89-8710-4db2-f51c-1b2de4676105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchdata==0.6.0\n",
            "  Downloading torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.31.0)\n",
            "Collecting torch==2.0.0 (from torchdata==0.6.0)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (3.1.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->torchdata==0.6.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->torchdata==0.6.0) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->torchdata==0.6.0) (0.41.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->torchdata==0.6.0) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.6.0) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->torchdata==0.6.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->torchdata==0.6.0) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchdata\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\n",
            "torchtext 0.15.2 requires torchdata==0.6.1, but you have torchdata 0.6.0 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchdata==0.6.0 # to be compatible with torch 2.0\n",
        "!pip install portalocker>=2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#torch specific\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Data loader\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "\n",
        "\n",
        "#text lib\n",
        "import torchtext\n",
        "\n",
        "#fetch data\n",
        "from torchtext.datasets import AG_NEWS\n",
        "\n",
        "# tokenizer\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "#build vocabulary\n",
        "from torchtext.vocab import vocab\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "# get input_ids (numericalization)\n",
        "from torchtext.transforms import VocabTransform\n",
        "\n",
        "# get embeddings\n",
        "from torch.nn import Embedding\n",
        "\n",
        "# get rnn model and layers\n",
        "from torch.nn import RNN, Linear, Sigmoid, Softmax\n",
        "\n",
        "# optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "# utils\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch.nn.utils.rnn import pad_packed_sequence"
      ],
      "metadata": {
        "id": "VhT8H3dHFYaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rKLxL7cpGXlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('./data',exist_ok=True)\n",
        "train_samples = AG_NEWS(root='./data',split='train')\n",
        "print('Number of training samples: ',len(list(train_samples)))\n",
        "print('A sample: \\n',next(iter(train_samples)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PH7vVIjlGrZQ",
        "outputId": "dcce041c-ea16-44f0-8d60-0c2b1c62a575"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples:  120000\n",
            "A sample: \n",
            " (3, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = get_tokenizer(tokenizer=\"basic_english\",language='en')"
      ],
      "metadata": {
        "id": "EvxRn-IDG3gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['This is called tokenization!','this is not the best approach by the way']\n",
        "token_list = [tokenizer(sentence) for sentence in text]\n",
        "print(token_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLqoKLXKHB15",
        "outputId": "09fd74f4-a31a-4348-ad4d-13b6e7381616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['this', 'is', 'called', 'tokenization', '!'], ['this', 'is', 'not', 'the', 'best', 'approach', 'by', 'the', 'way']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# token iterator\n",
        "def yield_tokens(corpus):\n",
        "  for (label,sentence) in corpus:\n",
        "    yield tokenizer(sentence)"
      ],
      "metadata": {
        "id": "n3GjsNEAHUYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = build_vocab_from_iterator(yield_tokens(train_samples),min_freq=100,specials=['<pad>','<unk>'])\n",
        "v.set_default_index(v['<unk>']) # index of OOV"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UL_2z3GHapj",
        "outputId": "e5f2ad2b-449c-4686-a43b-d5e6675bc897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(v['deep'],v['learning'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SWFra0vIjhE",
        "outputId": "e4090767-6740-43d0-a891-aaebf69272aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2162 4700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transform = VocabTransform(v)\n",
        "\n",
        "for sample in train_samples:\n",
        "  input_ids = vocab_transform(tokenizer(sample[1])) # 0th index is a label\n",
        "  print(input_ids)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I2DwuREIy58",
        "outputId": "cc5e593b-70ac-43fa-d6a1-110dab71b3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[432, 426, 2, 1606, 1, 114, 67, 3, 849, 14, 28, 15, 28, 16, 1, 4, 432, 375, 17, 10, 1, 7, 1, 4, 43, 4010, 784, 326, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_ids(sample):\n",
        "  tokens = tokenizer(sample[1]) # again, oth index is a label\n",
        "  return torch.LongTensor(vocab_transform(tokens))"
      ],
      "metadata": {
        "id": "5czrqKj7I051"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = Embedding(num_embeddings = len(v),embedding_dim=6,padding_idx=0)"
      ],
      "metadata": {
        "id": "IamV7HOQJXL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in train_samples:\n",
        "  input_ids = get_input_ids(sample)\n",
        "  print(input_ids)\n",
        "  print(embedding(input_ids))\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDKQ6XJqJx8r",
        "outputId": "0ff70533-7a58-4c92-f8ca-a7725561b692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 432,  426,    2, 1606,    1,  114,   67,    3,  849,   14,   28,   15,\n",
            "          28,   16,    1,    4,  432,  375,   17,   10,    1,    7,    1,    4,\n",
            "          43, 4010,  784,  326,    2])\n",
            "tensor([[ 0.6501, -0.1928, -2.2136,  0.2353, -1.4875, -0.5320],\n",
            "        [ 1.1267,  1.8755, -0.0230,  0.1487,  0.1805, -0.1433],\n",
            "        [-0.7042, -0.1911,  1.3894, -0.5377, -0.6318,  0.0080],\n",
            "        [ 0.3692, -1.0841, -0.1932, -0.3323, -0.0788, -0.2880],\n",
            "        [-0.9397, -0.5662, -0.0467,  0.2801, -0.7259,  0.0396],\n",
            "        [ 0.8393,  0.3802,  0.2668, -0.2152, -0.8384, -1.2904],\n",
            "        [ 0.5632, -0.3148, -1.0201,  1.3652, -0.2572, -0.8222],\n",
            "        [ 1.5739, -1.0177,  0.2626, -0.3058, -0.6208, -0.2340],\n",
            "        [-0.9553,  0.3795, -0.2180,  0.3681, -0.1209, -0.7572],\n",
            "        [ 0.4704, -0.2824,  0.9410,  0.0526, -1.6643,  0.7100],\n",
            "        [-0.1172, -0.0592,  0.3631,  0.8544,  1.3885, -0.3067],\n",
            "        [-1.3740, -0.6994, -2.7269,  1.1591,  0.2955,  1.4775],\n",
            "        [-0.1172, -0.0592,  0.3631,  0.8544,  1.3885, -0.3067],\n",
            "        [-0.6796, -0.2486, -0.5494,  0.3724, -0.5628, -1.7970],\n",
            "        [-0.9397, -0.5662, -0.0467,  0.2801, -0.7259,  0.0396],\n",
            "        [-0.2879, -1.4675,  0.2858,  0.6899,  1.3290,  1.2351],\n",
            "        [ 0.6501, -0.1928, -2.2136,  0.2353, -1.4875, -0.5320],\n",
            "        [ 1.2269, -0.1353,  0.1227,  0.8990, -1.9626,  1.4602],\n",
            "        [ 0.5202,  1.0476,  0.5577, -0.7594, -0.9364, -2.2426],\n",
            "        [-0.6511,  2.1352, -0.1449, -1.7503,  1.6401, -0.8384],\n",
            "        [-0.9397, -0.5662, -0.0467,  0.2801, -0.7259,  0.0396],\n",
            "        [ 0.5989,  1.4051,  0.0376,  0.7311,  1.0605, -1.8685],\n",
            "        [-0.9397, -0.5662, -0.0467,  0.2801, -0.7259,  0.0396],\n",
            "        [-0.2879, -1.4675,  0.2858,  0.6899,  1.3290,  1.2351],\n",
            "        [-0.1384, -1.0411, -0.9531,  0.9155,  0.4677, -0.0465],\n",
            "        [ 0.2068,  0.8222,  0.2650, -0.0819,  0.1077,  1.3133],\n",
            "        [ 0.1695, -0.6735,  0.5348, -1.7127, -0.0537, -0.5472],\n",
            "        [-0.1041,  1.0634,  1.0523, -0.3061, -0.9087,  0.1158],\n",
            "        [-0.7042, -0.1911,  1.3894, -0.5377, -0.6318,  0.0080]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sample in train_samples:\n",
        "  input_ids = get_input_ids(sample)\n",
        "  print(input_ids.shape)\n",
        "  prompt = input('Continue?')\n",
        "  if prompt == 'y':\n",
        "    continue\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "Lt2IxqRzKIiK",
        "outputId": "62397cd6-6984-4cba-b32f-2c2da33aad2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([29])\n",
            "Continue?y\n",
            "torch.Size([42])\n",
            "Continue?y\n",
            "torch.Size([40])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3640b32ff242>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_input_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Continue?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [(1,'padding is necessary'),(4,'you know the reason right?')]\n",
        "batch_input_ids = [get_input_ids(sample) for sample in examples ]\n",
        "padded_input_ids = pad_sequence(batch_input_ids,batch_first=True,padding_value=0.0)"
      ],
      "metadata": {
        "id": "gLDMwwOEKK3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN1-KISSKj7q",
        "outputId": "1f523a38-3655-4f17-8328-1deb36fdcffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   1,   22, 4425,    0,    0,    0],\n",
            "        [ 166, 1200,    3, 2257,  480,   81]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_function(batch_samples):\n",
        "  '''\n",
        "  Input : Sample : (label,sentence)\n",
        "  return :  (label tensor, padded_seuence ,lengths of unpadded seq in batches)\n",
        "  '''\n",
        "\n",
        "  #padded_seq\n",
        "  batch_input_ids = [get_input_ids(sample) for sample in batch_samples ]\n",
        "\n",
        "  padded_input_ids = pad_sequence(batch_input_ids,batch_first=True,padding_value=0.0)\n",
        "\n",
        "  # label tensor\n",
        "  # -1 is added to make class num starting from 0, required for one-hot encoding\n",
        "  labels = torch.tensor([torch.LongTensor([sample[0]-1]) for sample in batch_samples])\n",
        "\n",
        "  # lengths of unpadded seq\n",
        "\n",
        "  lengths = [len(tokenizer(sample[1]))for sample in batch_samples]\n",
        "\n",
        "  return (labels,padded_input_ids,lengths)"
      ],
      "metadata": {
        "id": "0E6EZX3UKmY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label,sample,lengths = collate_function([(1,'this is great'),(2,'why is this taking such a long time?')])\n",
        "print('label tensor: \\n ',label)\n",
        "print('Padded sequence: \\n',sample)\n",
        "print('Actual lengths: ', lengths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "grL_mBrtLGOu",
        "outputId": "2f26358d-97de-42c0-d66e-7841d7135944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label tensor: \n",
            "  tensor([0, 1])\n",
            "Padded sequence: \n",
            " tensor([[  53,   22,  811,    0,    0,    0,    0,    0,    0],\n",
            "        [1165,   22,   53,  608,  560,    6,  443,  102,   81]])\n",
            "Actual lengths:  [3, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.embedding = Embedding(vocab_size, embed_dim,padding_idx=0)\n",
        "        self.rnn = RNN(embed_dim,hidden_dim,batch_first=True)\n",
        "        self.fc = Linear(hidden_dim, num_class)\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        # get embedding for padded sequence\n",
        "        x = self.embedding(x)\n",
        "        x = pack_padded_sequence(x,lengths=lengths,enforce_sorted=False,batch_first=True)\n",
        "\n",
        "        # get hidden states for all time steps, last time step h_T as packed sequence\n",
        "        x = self.rnn(x)\n",
        "        # get the final state h_T\n",
        "        x = self.fc(x[1])  # logits\n",
        "        return x"
      ],
      "metadata": {
        "id": "u9V6jy7CLX1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "dataloader = DataLoader(train_samples,batch_size=batch_size,collate_fn = collate_function,shuffle=True)"
      ],
      "metadata": {
        "id": "BNXMDD41L8fm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(v)\n",
        "embedding_dim = 300\n",
        "num_classes = 4\n",
        "hidden_dim = 60\n",
        "model = RNNClassifier(vocab_size,embedding_dim,hidden_dim,num_classes)\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2keqK9hOMNy3",
        "outputId": "57e6ebda-d3f8-484e-d785-fa30efe0e3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNClassifier(\n",
              "  (embedding): Embedding(5002, 300, padding_idx=0)\n",
              "  (rnn): RNN(300, 60, batch_first=True)\n",
              "  (fc): Linear(in_features=60, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Loss = nn.functional.cross_entropy\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "0hLObn5wMbeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.functional import one_hot\n",
        "for epoch in range(1):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        labels, samples,lengths = data\n",
        "        labels_ohe = torch.tensor(one_hot(labels,num_classes=4),dtype=torch.float32)\n",
        "        labels_ohe = labels_ohe.to(device)\n",
        "        samples = samples.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(samples,lengths)\n",
        "\n",
        "        loss = Loss(outputs.squeeze(), labels_ohe.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Loss\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "        class_correct = torch.argmax(outputs.to('cpu'),axis=2) == torch.as_tensor(labels)\n",
        "        running_acc += torch.count_nonzero(class_correct)/batch_size\n",
        "        if i % 100 == 99:    # print every 10000 mini-batches\n",
        "            print('[%d, %5d] loss: %.3f Accuracy:%.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 99,running_acc/99))\n",
        "            running_loss = 0.0\n",
        "            running_acc = 0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_Jn3dvuMiOQ",
        "outputId": "5deccb78-68b8-4cba-938c-7fd1721e88e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:297: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n",
            "<ipython-input-24-b25ab0097f06>:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels_ohe = torch.tensor(one_hot(labels,num_classes=4),dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   100] loss: 1.462 Accuracy:0.246\n",
            "[1,   200] loss: 1.460 Accuracy:0.234\n",
            "[1,   300] loss: 1.471 Accuracy:0.238\n",
            "[1,   400] loss: 1.456 Accuracy:0.234\n",
            "[1,   500] loss: 1.465 Accuracy:0.227\n",
            "[1,   600] loss: 1.458 Accuracy:0.233\n",
            "[1,   700] loss: 1.461 Accuracy:0.244\n",
            "[1,   800] loss: 1.456 Accuracy:0.240\n",
            "[1,   900] loss: 1.462 Accuracy:0.240\n",
            "[1,  1000] loss: 1.452 Accuracy:0.251\n",
            "[1,  1100] loss: 1.459 Accuracy:0.250\n",
            "[1,  1200] loss: 1.458 Accuracy:0.246\n",
            "[1,  1300] loss: 1.455 Accuracy:0.251\n",
            "[1,  1400] loss: 1.470 Accuracy:0.236\n",
            "[1,  1500] loss: 1.443 Accuracy:0.250\n",
            "[1,  1600] loss: 1.452 Accuracy:0.247\n",
            "[1,  1700] loss: 1.464 Accuracy:0.242\n",
            "[1,  1800] loss: 1.451 Accuracy:0.245\n",
            "[1,  1900] loss: 1.457 Accuracy:0.261\n",
            "[1,  2000] loss: 1.456 Accuracy:0.244\n",
            "[1,  2100] loss: 1.457 Accuracy:0.242\n",
            "[1,  2200] loss: 1.450 Accuracy:0.259\n",
            "[1,  2300] loss: 1.447 Accuracy:0.250\n",
            "[1,  2400] loss: 1.447 Accuracy:0.261\n",
            "[1,  2500] loss: 1.450 Accuracy:0.246\n",
            "[1,  2600] loss: 1.467 Accuracy:0.243\n",
            "[1,  2700] loss: 1.440 Accuracy:0.268\n",
            "[1,  2800] loss: 1.458 Accuracy:0.254\n",
            "[1,  2900] loss: 1.460 Accuracy:0.247\n",
            "[1,  3000] loss: 1.443 Accuracy:0.246\n",
            "[1,  3100] loss: 1.456 Accuracy:0.251\n",
            "[1,  3200] loss: 1.458 Accuracy:0.244\n",
            "[1,  3300] loss: 1.441 Accuracy:0.253\n",
            "[1,  3400] loss: 1.445 Accuracy:0.256\n",
            "[1,  3500] loss: 1.457 Accuracy:0.255\n",
            "[1,  3600] loss: 1.449 Accuracy:0.260\n",
            "[1,  3700] loss: 1.456 Accuracy:0.245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"all the focus is now on the biggest T20 league in the world \"\n",
        "text = \"The league uses a lot of technologies to trace the ball \""
      ],
      "metadata": {
        "id": "-VlyVDmJM5mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['World','Sports','Business','Sci-Tech']"
      ],
      "metadata": {
        "id": "eHasdwPWNc88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_ids_inf(text):\n",
        "  tokens = tokenizer(text)\n",
        "  input_ids = vocab_transform(tokens)\n",
        "  return torch.LongTensor(input_ids).unsqueeze(0)"
      ],
      "metadata": {
        "id": "SXA4xerxNdob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_inference = model.to('cpu')\n",
        "with torch.inference_mode(True):\n",
        "  logits = model_inference(get_input_ids_inf(text),[len(tokenizer(text))])\n",
        "  scores = torch.nn.functional.softmax(logits,dim=2)\n",
        "  print(scores)\n",
        "  print(classes[torch.argmax(scores)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVGsjr0YNhjh",
        "outputId": "f4f4ce50-d5d1-4b64-ebd5-0aa6bf2b9c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[0.3417, 0.1478, 0.2527, 0.2577]]])\n",
            "World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = torch.randint(low=0,high=255,size=(4,6,3))\n",
        "print(img.shape)\n",
        "print(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FU25qPMCN28c",
        "outputId": "62340c34-be0f-42d9-de10-e87e5308df5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 6, 3])\n",
            "tensor([[[  8, 155, 197],\n",
            "         [ 60, 101, 240],\n",
            "         [134,  35, 118],\n",
            "         [ 49, 216, 148],\n",
            "         [112, 194, 123],\n",
            "         [191, 249, 202]],\n",
            "\n",
            "        [[159, 195, 244],\n",
            "         [ 43,  39, 208],\n",
            "         [161,   2, 148],\n",
            "         [196, 220, 132],\n",
            "         [202,  31, 113],\n",
            "         [ 23,  19, 204]],\n",
            "\n",
            "        [[ 40, 242,  74],\n",
            "         [ 70, 153, 123],\n",
            "         [167, 138,  56],\n",
            "         [170, 213, 168],\n",
            "         [207,  64, 137],\n",
            "         [ 55,  90, 130]],\n",
            "\n",
            "        [[116, 240,  90],\n",
            "         [ 22, 125, 235],\n",
            "         [ 56, 125, 162],\n",
            "         [191,  40, 156],\n",
            "         [154,  92,  80],\n",
            "         [104, 169, 247]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.permute(img,(2,0,1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7rNg8eFT5Nt",
        "outputId": "88073e3e-b326-48c3-d27e-4f7e01711e5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 100, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(img,dim=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WalSNkHOUIWf",
        "outputId": "a9d7419c-6d96-495b-e780-bc1a08eae6d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 554,  950, 1028],\n",
              "        [ 784,  506, 1049],\n",
              "        [ 709,  900,  688],\n",
              "        [ 643,  791,  970]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SE417YYGUW-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}